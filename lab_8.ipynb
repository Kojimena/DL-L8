{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 8\n",
    "- Jimena Hern√°ndez\n",
    "- Mark Albrand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oct 12 2009 \tNice trendy hotel location not too bad.\tI stayed in this hotel for one night. As this i\n"
     ]
    }
   ],
   "source": [
    "file = \"data/reviews_data.txt\"\n",
    "\n",
    "text_content = \"\"\n",
    "with open(file, 'r', encoding='latin-1') as file:\n",
    "    text_content = file.read()\n",
    "\n",
    "print(text_content[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" documents = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Artificial intelligence is transforming the world rapidly.\",\n",
    "    \"Python is an incredibly versatile programming language.\",\n",
    "    \"She sells seashells by the seashore on a sunny day.\",\n",
    "    \"Data science involves statistics, coding, and domain expertise.\",\n",
    "    \"In the heart of the forest, the birds sing their morning song.\",\n",
    "    \"Space exploration has always captured the imagination of humanity.\",\n",
    "    \"The coffee machine broke just before the morning rush.\",\n",
    "    \"Quantum computing could revolutionize cryptography and data security.\",\n",
    "    \"A warm cup of tea can be soothing on a cold winter evening.\"\n",
    "] \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_documents = [line.lower().split() for line in text_content.split('\\n') if line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['oct', '12', '2009', 'nice', 'trendy', 'hotel', 'location', 'not', 'too', 'bad.', 'i', 'stayed', 'in', 'this', 'hotel', 'for', 'one', 'night.', 'as', 'this', 'is', 'a', 'fairly', 'new', 'place', 'some', 'of', 'the', 'taxi', 'drivers', 'did', 'not', 'know', 'where', 'it', 'was', 'and/or', 'did', 'not', 'want', 'to', 'drive', 'there.', 'once', 'i', 'have', 'eventually', 'arrived', 'at', 'the', 'hotel,', 'i', 'was', 'very', 'pleasantly', 'surprised', 'with', 'the', 'decor', 'of', 'the', 'lobby/ground', 'floor', 'area.', 'it', 'was', 'very', 'stylish', 'and', 'modern.', 'i', 'found', 'the', \"reception's\", 'staff', 'geeting', 'me', 'with', \"'aloha'\", 'a', 'bit', 'out', 'of', 'place,', 'but', 'i', 'guess', 'they', 'are', 'briefed', 'to', 'say', 'that', 'to', 'keep', 'up', 'the', 'coroporate', 'image.as', 'i', 'have', 'a', 'starwood', 'preferred', 'guest', 'member,', 'i', 'was', 'given', 'a', 'small', 'gift', 'upon-check', 'in.', 'it', 'was', 'only', 'a', 'couple', 'of', 'fridge', 'magnets', 'in', 'a', 'gift', 'box,', 'but', 'nevertheless', 'a', 'nice', 'gesture.my', 'room', 'was', 'nice', 'and', 'roomy,', 'there', 'are', 'tea', 'and', 'coffee', 'facilities', 'in', 'each', 'room', 'and', 'you', 'get', 'two', 'complimentary', 'bottles', 'of', 'water', 'plus', 'some', 'toiletries', 'by', \"'bliss'.the\", 'location', 'is', 'not', 'great.', 'it', 'is', 'at', 'the', 'last', 'metro', 'stop', 'and', 'you', 'then', 'need', 'to', 'take', 'a', 'taxi,', 'but', 'if', 'you', 'are', 'not', 'planning', 'on', 'going', 'to', 'see', 'the', 'historic', 'sites', 'in', 'beijing,', 'then', 'you', 'will', 'be', 'ok.i', 'chose', 'to', 'have', 'some', 'breakfast', 'in', 'the', 'hotel,', 'which', 'was', 'really', 'tasty', 'and', 'there', 'was', 'a', 'good', 'selection', 'of', 'dishes.', 'there', 'are', 'a', 'couple', 'of', 'computers', 'to', 'use', 'in', 'the', 'communal', 'area,', 'as', 'well', 'as', 'a', 'pool', 'table.', 'there', 'is', 'also', 'a', 'small', 'swimming', 'pool', 'and', 'a', 'gym', 'area.i', 'would', 'definitely', 'stay', 'in', 'this', 'hotel', 'again,', 'but', 'only', 'if', 'i', 'did', 'not', 'plan', 'to', 'travel', 'to', 'central', 'beijing,', 'as', 'it', 'can', 'take', 'a', 'long', 'time.', 'the', 'location', 'is', 'ok', 'if', 'you', 'plan', 'to', 'do', 'a', 'lot', 'of', 'shopping,', 'as', 'there', 'is', 'a', 'big', 'shopping', 'centre', 'just', 'few', 'minutes', 'away', 'from', 'the', 'hotel', 'and', 'there', 'are', 'plenty', 'of', 'eating', 'options', 'around,', 'including', 'restaurants', 'that', 'serve', 'a', 'dog', 'meat!'], ['sep', '25', '2009', 'great', 'budget', 'hotel!', 'stayed', 'two', 'nights', 'at', 'aloft', 'on', 'the', 'most', 'recent', 'trip', 'to', 'china.', 'the', 'hotel', 'was', 'very', 'modern', 'and', 'clean.', 'the', 'room', 'was', 'spotless', 'and', 'a', 'comfortable', 'king', 'sized', 'bed', '(as', 'far', 'as', 'soft', 'beds', 'go', 'in', 'china).', 'the', 'staff', 'was', 'very', 'punctual', 'and', 'went', 'out', 'of', 'the', 'way', 'to', 'help', 'my', 'every', 'need,', 'including', 'going', 'to', 'a', 'store', 'across', 'the', 'street', 'to', 'purchase', 'a', 'china', 'mobile', 'sim', 'card', 'for', 'me.', 'the', 'buffet', 'breakfast', 'was', 'okay,', 'nothing', 'to', 'write', 'home', 'about.', 'the', '42\\x94', 'lcd', 'screen', 'had', 'movies', 'on', 'demand', 'for', '20rmb', 'and', 'had', 'a', 'good', 'selection', 'of', 'western', 'channels', 'including', 'hbo,', 'cnn,', 'bbc,', 'star', 'world', 'etc', 'the', 'gym', 'was', 'small,', 'had', 'a', 'selection', 'of', 'basic', 'weights', 'and', 'one', 'cable', 'machine,', 'there', 'was', 'however', '6', 'new', 'technogym', 'cardio', 'machines', 'with', 'built', 'in', 'lcd', 'tvs', 'which', 'were', 'very', 'good.', 'the', 'location', 'is', 'a', 'bit', 'out', 'of', 'the', 'way', 'to', 'the', 'central', 'areas', 'of', 'beijing,', 'but', 'it', 'is', 'better', 'suited', 'for', 'my', 'needs', 'as', 'i', 'need', 'to', 'be', 'in', 'the', 'haidian', 'district.', 'being', 'spg', 'platinum', 'there', 'were', 'no', 'upgrades', 'to', 'a', 'better', 'room,', 'because', 'aloft', 'has', 'a', 'policy', 'of', 'not', 'doing', 'any', 'upgrades.', 'the', 'sheraton', 'next', 'door', 'is', 'a', 'much', 'nicer', 'hotel', 'in', 'my', 'opinion', '(where', 'i', 'am', 'writing', 'this', 'from', 'now,', 'with', 'an', 'upgraded', 'room)', 'but', 'as', 'far', 'as', 'bang', 'for', 'the', 'buck,', 'aloft', 'is', 'a', 'great', 'place!']]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_documents[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 184)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear el modelo Word2Vec\n",
    "model = Word2Vec(\n",
    "    tokenized_documents,\n",
    "    vector_size=50,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=10\n",
    ")\n",
    "\n",
    "model.train(tokenized_documents, total_examples=len(tokenized_documents), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('coding,', 0.3250468671321869), ('song.', 0.2955818474292755), ('expertise.', 0.22256843745708466)]\n"
     ]
    }
   ],
   "source": [
    "similar_words = model.wv.most_similar('machine', topn=3)\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.56363770e-02 -1.90207418e-02 -4.05694736e-04  6.93504512e-03\n",
      " -1.87967077e-03  1.67634841e-02  1.80184375e-02  1.30748404e-02\n",
      " -1.42475578e-03  1.54197486e-02 -1.70646980e-02  6.41230494e-03\n",
      " -9.27368738e-03 -1.01767350e-02  7.18082907e-03  1.07411928e-02\n",
      "  1.55367181e-02 -1.15312962e-02  1.48676634e-02  1.32469134e-02\n",
      " -7.42002204e-03 -1.74926557e-02  1.08768437e-02  1.30189145e-02\n",
      " -1.57641794e-03 -1.34170018e-02 -1.41690243e-02 -4.99411114e-03\n",
      "  1.02887480e-02 -7.32928282e-03 -1.87415890e-02  7.65435817e-03\n",
      "  9.76990722e-03 -1.28525477e-02  2.42000283e-03 -4.14695358e-03\n",
      "  5.11084909e-05 -1.97666250e-02  5.38482517e-03 -9.49984975e-03\n",
      "  2.17539258e-03 -3.15230014e-03  4.38969163e-03 -1.57610700e-02\n",
      " -5.43577783e-03  5.32547431e-03  1.06922062e-02 -4.78471350e-03\n",
      " -1.90206673e-02  9.00904741e-03]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv['is'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
